{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4_s8h-ilzHQc"
      },
      "source": [
        "# StyleGAN2 -> Style-Mixing\n",
        "\n",
        "***AmirHossein Bayat & Melika Emami***\n",
        "\n",
        "This notebook demonstrates how to run NVIDIA's StyleGAN2 on Google Colab to do Style Mixing With your custom photo.\n",
        "Make sure to specify a GPU runtime.\n",
        "\n",
        "For information on StyleGAN2, see:\n",
        "\n",
        "Paper: https://arxiv.org/abs/1812.04948\n",
        "\n",
        "Video: https://youtu.be/kSLJriaOumA\n",
        "\n",
        "Code: https://github.com/NVlabs/stylegan\n",
        "\n",
        "FFHQ: https://github.com/NVlabs/ffhq-dataset\n",
        "\n",
        "/Mikael Christensen, 2019.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "colab_type": "code",
        "id": "PzDuIoMcqfBT",
        "outputId": "74e426de-a0f1-4b53-d1a0-2ea36994263a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tensorflow version: 1.14.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "c:\\Users\\talha\\miniconda3\\envs\\my\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU 0: NVIDIA GeForce RTX 3050 Ti Laptop GPU (UUID: GPU-5d3a4de4-497c-1ad3-8ff6-24079d58178c)\n",
            "GPU Identified at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Download the code\n",
        "# !git clone https://github.com/NVlabs/stylegan2.git\n",
        "# %cd stylegan2\n",
        "# !nvcc test_nvcc.cu -o test_nvcc -run\n",
        "\n",
        "print('Tensorflow version: {}'.format(tf.__version__) )\n",
        "!nvidia-smi -L\n",
        "print('GPU Identified at: {}'.format(tf.test.gpu_device_name()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "colab_type": "code",
        "id": "Mz23RJ-RgPME",
        "outputId": "0966d8ab-98a0-4f40-e6bb-5c970a0f706b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "FupSIgCZ3rj7"
      },
      "source": [
        "**Required Files**\n",
        "\n",
        "Now you need to add below files to your google drive. Make sure you change path of files if needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "6R-VCNwhgedt",
        "outputId": "80fbf5bb-56d0-4f97-8238-3fae262a5db3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'!mkdir ffhq_dataset\\n!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/__init__.py\" \"/content/stylegan2/ffhq_dataset/__init__.py\"\\n!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/face_alignment.py\" \"/content/stylegan2/ffhq_dataset/face_alignment.py\"\\n!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/landmarks_detector.py\" \"/content/stylegan2/ffhq_dataset/landmarks_detector.py\"\\n!cp \"/content/drive/My Drive/StyleGAN2/align_images.py\" \"/content/stylegan2/align_images.py\"\\n!mkdir Pictures\\n!cp \"/content/drive/My Drive/StyleGAN2/Pic1.JPG\" \"/content/stylegan2/Pictures/Pic1.JPG\"\\n!cp \"/content/drive/My Drive/StyleGAN2/Pic2.JPG\" \"/content/stylegan2/Pictures/Pic2.JPG\"\\n!cp \"/content/drive/My Drive/StyleGAN2/Pic3.JPG\" \"/content/stylegan2/Pictures/Pic3.JPG\"\\n!cp \"/content/drive/My Drive/StyleGAN2/Pic4.jpg\" \"/content/stylegan2/Pictures/Pic4.JPG\"\\n!mkdir aligned_pictures'"
            ]
          },
          "execution_count": 64,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Projector files to convert given photos to dlatent vectors. I've changed a few things in original files from StyleGAN2, so you need to upload these files.\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/run_projector.py\" \"/content/stylegan2/run_projector.py\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/projector.py\" \"/content/stylegan2/projector.py\"\n",
        "# These files are used to align the given pictures and export the face part from it.\n",
        "!mkdir ffhq_dataset\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/__init__.py\" \"/content/stylegan2/ffhq_dataset/__init__.py\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/face_alignment.py\" \"/content/stylegan2/ffhq_dataset/face_alignment.py\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/ffhq_dataset/landmarks_detector.py\" \"/content/stylegan2/ffhq_dataset/landmarks_detector.py\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/align_images.py\" \"/content/stylegan2/align_images.py\"\n",
        "# In this part you have to specify your custom pictures to be used. I've named my pictures like below.\n",
        "!mkdir Pictures\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/Pic1.JPG\" \"/content/stylegan2/Pictures/Pic1.JPG\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/Pic2.JPG\" \"/content/stylegan2/Pictures/Pic2.JPG\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/Pic3.JPG\" \"/content/stylegan2/Pictures/Pic3.JPG\"\n",
        "!cp \"/content/drive/My Drive/StyleGAN2/Pic4.jpg\" \"/content/stylegan2/Pictures/Pic4.JPG\"\n",
        "# Make a folder to save aligned pictures in it.\n",
        "!mkdir aligned_pictures"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting dlib\n",
            "  Using cached dlib-19.24.1-cp37-cp37m-win_amd64.whl\n",
            "Installing collected packages: dlib\n",
            "Successfully installed dlib-19.24.1\n"
          ]
        }
      ],
      "source": [
        "!pip install dlib"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VFF5yfvA5UNz"
      },
      "source": [
        "**Aligning Pictures**\n",
        "\n",
        "Now you need to run the align_images.py to do the aligning. Parameters are the folder containing your pictures and the folder to save the aligned pictures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "ZoxEbwwtjkwO",
        "outputId": "53e68504-72a3-4d7d-c7a5-3c82f767a56a"
      },
      "outputs": [],
      "source": [
        "%run align_images.py Pictures/ aligned_pictures/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Pen-j5ij5s6j"
      },
      "source": [
        "**Generate .tfrecords**\n",
        "\n",
        "We use the dataset_tool.py from StyleGAN2 to convert aligned pictures to tfrecords files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "colab_type": "code",
        "id": "jC_I6IOjc1KT",
        "outputId": "781fc81a-a3c2-4570-efe6-789531af7f71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading images from \"aligned_pictures\"\n",
            "Creating dataset \"Datasets\"\n",
            "0 / 4\r"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dataset_tool.py:86: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Added 4 images.                         \n"
          ]
        }
      ],
      "source": [
        "%run dataset_tool.py create_from_images Datasets aligned_pictures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JyIv8Svm6EVc"
      },
      "source": [
        "**Projecting pictures**\n",
        "\n",
        "In this part we use our customized run_projector.py file to the image projection. We set the network parameter to StyleGAN2-ffhq-config-f and Project only one of our converted pictures. (You can change the --num-images to whatever you want. The default step parameter for this part is set to 1500 which you can change on **projector.py** file. After running this part some .npy files containing dlatents will generate in results folder related to each picture.(There's a little bug here which does not affect our work.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install ninja"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "xNg_QellgTnu"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "Could not find MSVC/GCC/CLANG installation on this computer. Check compiler_bindir_search_path list in \"c:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\tflib\\custom_ops.py\".",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\run_projector.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;31m#----------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\run_projector.py\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[1;34m'project-real-images'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'run_projector.project_real_images'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m     }\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mdnnlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc_name_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msubcmd\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;31m#----------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\submission\\submit.py\u001b[0m in \u001b[0;36msubmit_run\u001b[1;34m(submit_config, run_func_name, **run_func_kwargs)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[0mfarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfinalize_submit_config\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost_run_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[0m_populate_run_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost_run_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 343\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mfarm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhost_run_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\submission\\internal\\local.py\u001b[0m in \u001b[0;36msubmit\u001b[1;34m(self, submit_config, host_run_dir)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubmit\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrun_wrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'- run_dir: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mconvert_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflush\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mrun_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\submission\\submit.py\u001b[0m in \u001b[0;36mrun_wrapper\u001b[1;34m(submit_config)\u001b[0m\n\u001b[0;32m    278\u001b[0m             \u001b[0mrun_func_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_func_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 280\u001b[1;33m             \u001b[0mrun_func_obj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_func_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    281\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    282\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"dnnlib: Finished {0}() in {1}.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubmit_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_func_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_time\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\run_projector.py\u001b[0m in \u001b[0;36mproject_real_images\u001b[1;34m(network_pkl, dataset_name, data_dir, num_images, num_snapshots)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mproject_real_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_pkl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_snapshots\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading networks from \"%s\"...'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mnetwork_pkl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m     \u001b[0m_G\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpretrained_networks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_networks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork_pkl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m     \u001b[0mproj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprojector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mProjector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[0mproj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\pretrained_networks.py\u001b[0m in \u001b[0;36mload_networks\u001b[1;34m(path_or_gdrive_path)\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[0mtflib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_tf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 76\u001b[1;33m         \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstream\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'latin1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     77\u001b[0m     \u001b[0m_cached_networks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpath_or_url\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\tflib\\network.py\u001b[0m in \u001b[0;36m__setstate__\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m    295\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    296\u001b[0m         \u001b[1;31m# Init TensorFlow graph.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 297\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_own_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m         \u001b[0mtfutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_vars\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_var\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"variables\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\tflib\\network.py\u001b[0m in \u001b[0;36m_init_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# ignore surrounding control dependencies\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_templates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m                 \u001b[0mout_expr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_templates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mbuild_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         \u001b[1;31m# Collect outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mG_synthesis_stylegan2\u001b[1;34m(dlatents_in, dlatent_size, num_channels, resolution, fmap_base, fmap_decay, fmap_min, fmap_max, randomize_noise, architecture, nonlinearity, dtype, resample_kernel, fused_modconv, **_kwargs)\u001b[0m\n",
            "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mlayer\u001b[1;34m(x, layer_idx, fmaps, kernel, up)\u001b[0m\n",
            "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mmodulated_conv2d_layer\u001b[1;34m(x, y, fmaps, kernel, up, down, demodulate, resample_kernel, gain, use_wscale, lrmul, fused_modconv, weight_var, mod_weight_var, mod_bias_var)\u001b[0m\n",
            "\u001b[1;32m<string>\u001b[0m in \u001b[0;36mapply_bias_act\u001b[1;34m(x, act, alpha, gain, lrmul, bias_var)\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\tflib\\ops\\fused_bias_act.py\u001b[0m in \u001b[0;36mfused_bias_act\u001b[1;34m(x, b, axis, act, alpha, gain, impl)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;34m'cuda'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_fused_bias_act_cuda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m     }\n\u001b[1;32m---> 68\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mimpl_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimpl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;31m#----------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\tflib\\ops\\fused_bias_act.py\u001b[0m in \u001b[0;36m_fused_bias_act_cuda\u001b[1;34m(x, b, axis, act, alpha, gain)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \u001b[1;31m# CUDA kernel.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[0mcuda_kernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfused_bias_act\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[0mcuda_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mact_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda_idx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\tflib\\ops\\fused_bias_act.py\u001b[0m in \u001b[0;36m_get_plugin\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_get_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mcustom_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_plugin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.cu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#----------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\tflib\\custom_ops.py\u001b[0m in \u001b[0;36mget_plugin\u001b[1;34m(cuda_file)\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[0mtmp_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcuda_file_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_tmp'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcuda_file_ext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[0m_run_cmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prepare_nvcc_cli\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\"%s\" --preprocess -o \"%s\" --keep --keep-dir \"%s\"'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcuda_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m                 \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m                     \u001b[0mbad_file_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'\"'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcuda_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\\\'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'/'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# __FILE__ in error check macros\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m                     \u001b[0mgood_file_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'\"'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcuda_file_base\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mc:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\tflib\\custom_ops.py\u001b[0m in \u001b[0;36m_prepare_nvcc_cli\u001b[1;34m(opts)\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'nt'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Could not find MSVC/GCC/CLANG installation on this computer. Check compiler_bindir_search_path list in \"%s\".'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m__file__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[0mcmd\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' --compiler-bindir \"%s\"'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcompiler_bindir\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;34m' 2>&1'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: Could not find MSVC/GCC/CLANG installation on this computer. Check compiler_bindir_search_path list in \"c:\\Users\\talha\\Downloads\\StyleGAN2_Style-Mixing-master\\StyleGAN2_Style-Mixing-master\\stylegan2\\dnnlib\\tflib\\custom_ops.py\"."
          ]
        }
      ],
      "source": [
        "%run run_projector.py project-real-images --network=stylegan2-ffhq-config-f.pkl --dataset=Datasets --data-dir=. --num-images=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wKxs_BHp7KcB"
      },
      "source": [
        "**Style Mixing Function**\n",
        "\n",
        "In this function we load the network and use it to map some given seed to dlatent vectors as **Style**. The dlatent parameter is the loaded .npy files which we generated in the previous step."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_J7Rqn8BDY-g"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import PIL.Image\n",
        "import dnnlib\n",
        "import dnnlib.tflib as tflib\n",
        "import re\n",
        "import sys\n",
        "\n",
        "import pretrained_networks\n",
        "\n",
        "def style_mixing(dlatent, col_seeds, truncation_psi, col_styles, minibatch_size=4):\n",
        "    print('Loading networks from ...')\n",
        "    _G, _D, Gs = pretrained_networks.load_networks('gdrive:networks/stylegan2-ffhq-config-f.pkl')\n",
        "    w_avg = Gs.get_var('dlatent_avg') # [component]\n",
        "    row_seeds = [80]\n",
        "    Gs_syn_kwargs = dnnlib.EasyDict()\n",
        "    Gs_syn_kwargs.output_transform = dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True)\n",
        "    Gs_syn_kwargs.randomize_noise = False\n",
        "    Gs_syn_kwargs.minibatch_size = 1 #minibatch_size\n",
        "\n",
        "    print('Generating W vectors...')\n",
        "    all_seeds = list(set(col_seeds))\n",
        "    all_z = np.stack([np.random.RandomState(seed).randn(*Gs.input_shape[1:]) for seed in all_seeds]) # [minibatch, component]\n",
        "\n",
        "    all_w = Gs.components.mapping.run(all_z, None) # [minibatch, layer, component]\n",
        "    all_w = np.concatenate((all_w, dlatent), 0)\n",
        "    all_w = w_avg + (all_w - w_avg) * truncation_psi # [minibatch, layer, component]\n",
        "    all_seeds.extend(row_seeds) #= list(set(col_seeds + row_seeds))\n",
        "    w_dict = {seed: w for seed, w in zip(all_seeds, list(all_w))} # [layer, component]\n",
        "    \n",
        "    print('Generating images...')\n",
        "    all_images = Gs.components.synthesis.run(all_w, **Gs_syn_kwargs) # [minibatch, height, width, channel]\n",
        "    image_dict = {(seed, seed): image for seed, image in zip(all_seeds, list(all_images))}\n",
        "\n",
        "    print('Generating style-mixed images...')\n",
        "    for row_seed in row_seeds:\n",
        "        for col_seed in col_seeds:\n",
        "            w = w_dict[row_seed].copy()\n",
        "            # We set col_styles in this part\n",
        "            w[3:8] = w_dict[col_seed][3:8]\n",
        "            image = Gs.components.synthesis.run(w[np.newaxis], **Gs_syn_kwargs)[0]\n",
        "            image_dict[(row_seed, col_seed)] = image\n",
        "\n",
        "    print('Saving images...')\n",
        "    for (row_seed, col_seed), image in image_dict.items():\n",
        "        PIL.Image.fromarray(image, 'RGB').save(dnnlib.make_run_dir_path('Mix/'+'%d-%d.png' % (row_seed, col_seed)))\n",
        "\n",
        "    print('Saving image grid...')\n",
        "    _N, _C, H, W = Gs.output_shape\n",
        "    canvas = PIL.Image.new('RGB', (W * (len(col_seeds) + 1), H * (len(row_seeds) + 1)), 'black')\n",
        "    for row_idx, row_seed in enumerate([None] + row_seeds):\n",
        "        for col_idx, col_seed in enumerate([None] + col_seeds):\n",
        "            if row_seed is None and col_seed is None:\n",
        "                continue\n",
        "            key = (row_seed, col_seed)\n",
        "            if row_seed is None:\n",
        "                key = (col_seed, col_seed)\n",
        "            if col_seed is None:\n",
        "                key = (row_seed, row_seed)\n",
        "            canvas.paste(PIL.Image.fromarray(image_dict[key], 'RGB'), (W * col_idx, H * row_idx))\n",
        "    canvas.save(dnnlib.make_run_dir_path('Mix/grid.png'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "t1uw5q9580as"
      },
      "source": [
        "Load some dlatent.npy file and pass it to function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Rh5eZxw9DqIy"
      },
      "outputs": [],
      "source": [
        "dlat = np.load('/content/stylegan2/results/00002-project-real-images/image0000--dlatent.npy')\n",
        "style_mixing(dlat, [44,55,1000,10,3,100,75,458,1500], 0.5, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "g_HRi6eR8_Tu"
      },
      "source": [
        "If you want to zip results folder to download it run the following cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "8ZWBP43KSx5U",
        "outputId": "1c8a3dbf-0d40-4aca-dfb6-3762bcfda24c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/content/stylegan2/resultszip.zip'"
            ]
          },
          "execution_count": 62,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import shutil\n",
        "\n",
        "zip_name = '/content/stylegan2/resultszip'\n",
        "directory_name = '/content/stylegan2/results'\n",
        "\n",
        "# Create 'path\\to\\zip_file.zip'\n",
        "shutil.make_archive(zip_name, 'zip', directory_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "StyleMixing with StyleGAN2",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
